{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.100605921Z",
     "start_time": "2023-07-29T13:37:14.052362279Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import networkx as nx\n",
    "from dateutil import relativedelta\n",
    "from datetime import datetime\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "con = sqlite3.connect('../data/interim/articles_with_author_mapping.db')\n",
    "cur = con.cursor()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.100806626Z",
     "start_time": "2023-07-29T13:37:14.100436278Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cur.execute(\"select id, name, abbreviation, matching_certainty from authors where abbreviation is not null\")\n",
    "rows = cur.fetchall()\n",
    "authors = pd.DataFrame(columns=[\"id\", \"name\", \"abbreviation\", \"certainty\"], data=rows)\n",
    "authors.set_index(\"id\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.172742774Z",
     "start_time": "2023-07-29T13:37:14.100696602Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# convert null to nans\n",
    "authors = authors.replace(\"null\", np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.220360466Z",
     "start_time": "2023-07-29T13:37:14.176345117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# set certainty of a row to the average certainty over all rows with same name and abbreviation, ignore nan values\n",
    "mean_certainty = authors.groupby([\"name\", \"abbreviation\"])[\"certainty\"].transform(lambda x: np.nanmean(x))\n",
    "authors[\"certainty\"] = mean_certainty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.264398866Z",
     "start_time": "2023-07-29T13:37:14.220209272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "authors[\"name_pointing_to_abbreviation_count\"] = authors.groupby([\"name\", \"abbreviation\"])[\"name\"].transform(\"count\")\n",
    "authors[\"abbreviation_pointing_to_name_count\"] = authors.groupby([\"name\", \"abbreviation\"])[\"abbreviation\"].transform(\"count\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.264882123Z",
     "start_time": "2023-07-29T13:37:14.264269095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# drop duplicates based on name, abbreviation, certainty. I can drop them because ..._count saved the count\n",
    "authors.drop_duplicates(subset=[\"name\", \"abbreviation\", \"certainty\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.277999092Z",
     "start_time": "2023-07-29T13:37:14.270513973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# set the share that the name has of all names that point to that abbreviation\n",
    "authors_with_name_pointing_to_abbreviation_sum =  authors.groupby([\"abbreviation\"]).agg(names_pointing_to_abbreviation_sum=(\"name_pointing_to_abbreviation_count\", \"sum\")).reset_index()\n",
    "authors = pd.merge(authors, authors_with_name_pointing_to_abbreviation_sum, on=\"abbreviation\")\n",
    "authors[\"name_pointing_to_abbreviation_share\"] = authors[\"name_pointing_to_abbreviation_count\"] / authors[\"names_pointing_to_abbreviation_sum\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.316498704Z",
     "start_time": "2023-07-29T13:37:14.275665749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# set the share that the abbreviation has of all abbreviations that point to that name\n",
    "authors_with_abbreviation_pointing_to_name_sum = authors.groupby([\"name\"]).agg(abbreviations_pointing_to_name_sum=(\"abbreviation_pointing_to_name_count\", \"sum\")).reset_index()\n",
    "authors = pd.merge(authors, authors_with_abbreviation_pointing_to_name_sum, on=\"name\")\n",
    "authors[\"abbreviation_pointing_to_name_share\"] = authors[\"abbreviation_pointing_to_name_count\"] / authors[\"abbreviations_pointing_to_name_sum\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.316756853Z",
     "start_time": "2023-07-29T13:37:14.316313235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# calculate a final score for the weighted edge between name and abbreviation\n",
    "authors[\"score\"] = authors[\"certainty\"] + authors[\"name_pointing_to_abbreviation_share\"] + authors[\"abbreviation_pointing_to_name_share\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.318269874Z",
     "start_time": "2023-07-29T13:37:14.316618842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# reduce the problem space to a bipartite graph, assigning all (name, abbreviation) pairs that are not connected to the graph as final/solved\n",
    "# add pairs to final mapping where abbreviation_pointing_to_name_count == 1 or name_pointing_to_abbreviation_count == 1 and remove those from the authors \n",
    "#one_to_one_mappings = authors[(authors[\"abbreviations_pointing_to_name_sum\"] == 1) & (authors[\"names_pointing_to_abbreviation_sum\"] == 1)]\n",
    "#final_mapping = pd.concat([final_mapping, one_to_one_mappings[[\"name\", \"abbreviation\"]]], ignore_index=True)\n",
    "\n",
    "#authors = authors[(authors[\"abbreviations_pointing_to_name_sum\"] != 1) | (authors[\"names_pointing_to_abbreviation_sum\"] != 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.360413284Z",
     "start_time": "2023-07-29T13:37:14.316720927Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# remove self referencing nodes\n",
    "authors = authors[authors[\"name\"].str.lower() != authors[\"abbreviation\"].str.lower()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.360677309Z",
     "start_time": "2023-07-29T13:37:14.360279371Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# add name and abbreviation as nodes list and remove duplicates\n",
    "nodes = list(authors[\"name\"].unique()) + list(authors[\"abbreviation\"].unique())\n",
    "\n",
    "# add unique edges based on entries in the authors table\n",
    "edges = []\n",
    "for index, row in authors.iterrows():\n",
    "    edges.append((row[\"name\"], row[\"abbreviation\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.360803794Z",
     "start_time": "2023-07-29T13:37:14.360392542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.clear()\n",
    "author_list = list(authors[\"name\"].unique())\n",
    "abbr_list = list(authors[authors[\"name\"].isin(author_list)][\"abbreviation\"].unique())\n",
    "G.add_nodes_from(author_list, bipartite=0)\n",
    "G.add_nodes_from(abbr_list, bipartite=1)\n",
    "dummy_nodes = [f\"{name}_dummy\" for name in author_list]\n",
    "G.add_nodes_from(dummy_nodes, bipartite=1)\n",
    "\n",
    "edges = []\n",
    "for index, row in authors[authors[\"name\"].isin(author_list) & authors[\"abbreviation\"].isin(abbr_list)].iterrows():\n",
    "    G.add_edges_from([(row[\"name\"], row[\"abbreviation\"])], weight=round(row[\"score\"],2) * -1)\n",
    "\n",
    "for name in author_list:\n",
    "    G.add_edges_from([(name, f\"{name}_dummy\")], weight=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.401975084Z",
     "start_time": "2023-07-29T13:37:14.360520872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "new_edges = nx.bipartite.minimum_weight_full_matching(G, top_nodes=list(authors[\"name\"].unique()), weight=\"weight\")\n",
    "g_new = nx.Graph()\n",
    "g_new.clear()\n",
    "g_new.add_nodes_from(author_list, bipartite=0)\n",
    "g_new.add_nodes_from(abbr_list, bipartite=1)\n",
    "g_new.add_edges_from(new_edges.items())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.438331851Z",
     "start_time": "2023-07-29T13:37:14.394705711Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "EdgeView([('Kai-Uwe Brandt', 'kub'), ('Nadja Topfstedt', 'jap'), ('Manfred Lüttich', 'Manfred Lüttich_dummy'), ('Magdalena Froehlich', 'mf'), ('Michael Frömmert', 'maf'), ('Heiko Trebs', 'ht'), ('Andreas Tappert', 'art'), ('Annett Riedel', 'ari'), ('Angelika Raulien', 'are'), ('Andrea Richter', 'ar'), ('Norbert Töpfer', 'nt'), ('Antje Henselin-Rudolph', 'ahr'), ('Nico Fliegner', 'nf'), ('Heike Liesaus', 'hl'), ('Juliane Streich', 'just'), ('Lisa Garn', 'lis'), ('Lisa Berins', 'la'), ('Melanie Steitz', 'mes'), ('Lisa Schliep', 'liep'), ('Kendra Reinhardt', 'kir'), ('Karoline Maria Keybe', 'Karoline Maria Keybe_dummy'), ('Karin Rieck', 'karin'), ('Karin Tamcke', 'Karin Tamcke_dummy'), ('Klaus Staeubert', 'kas'), ('Kay Würker', 'ka'), ('Kathrin Kabelitz', 'Kathrin Kabelitz_dummy'), ('Kai Kollenberg', 'kol'), ('Frank Pfütze', 'pfü'), ('Meike Strüber', 'mei'), ('Michael Dick', 'midi'), ('Manfred Hainich', 'Manfred Hainich_dummy'), ('Nikos Natsidis', 'nn'), ('Roland Heinrich', 'rohe'), ('Heinrich Lillie', 'hei'), ('Matthias Puppe', 'mpu'), ('Robert Nößler', 'nöß'), ('Roland Herold', 'rh'), ('Ditmar Wohlgemuth', 'dom'), ('Dominik Brüggemann', 'dbr'), ('Dominik Bath', 'Dominik Bath_dummy'), ('Dominic Welters', 'diw'), ('Matthias Roth', 'mro'), ('Manuel Niemann', 'mi'), ('Mathias Orbeck', 'mo'), ('Birgit Schöppenthau', 'bis'), ('Bastian Schröder', 'bas'), ('Christin Grödel', 'cg'), ('Christine Gräfe', 'cgr'), ('Steffen Brost', 'sb'), ('Krysta Brown', 'krysta'), ('Von Steffen Brost', 'bro'), ('Frank Schmidt', 'frs'), ('Frank Müller', 'fm'), ('Nina May', 'ny'), ('Von Heike Nyari', 'Von Heike Nyari_dummy'), ('Heike Nyari', 'nyari'), ('Guido Schäfer', 'gs'), ('Janina Fleischer', 'jaf'), ('Kathleen Retzar', 'kr'), ('Stephan Lohse', 'sl'), ('Stefan Lehmann', 'Stefan Lehmann_dummy'), ('Simone Liss', 'Simone Liss_dummy'), ('Holger Günther', 'hog'), ('Stefan Banitz', 'stb'), ('Jens Rosenkranz', 'joka'), ('Winfried Wächter', 'wer'), ('Andreas Dunte', 'ans'), ('Andreas Debski', 'ade'), ('Frauke Sievers', 'fs'), ('Frank Schober', 'Frank Schober_dummy'), ('Thomas Mayer', 'tom'), ('Thomas Meißner', 'Thomas Meißner_dummy'), ('Jens Rometsch', 'joh'), ('Jörg Reuter', 'jr'), ('Maria Keybe', 'mey'), ('Michael Strohmeyer', 'm strohmeyer'), ('Uwe Köster', 'ukö'), ('Julia Wick', 'Julia Wick_dummy'), ('Jörg Wolf', 'jw'), ('Thomas Steingen', 'totei'), ('Thomas Sparrer', 'tsa'), ('Alexander Bley', 'bly'), ('Ulrike Witt', 'uw'), ('Reik Anton', 'ra'), ('Florian Bamberg', 'fib'), ('Stefanie Büssing', 'Stefanie Büssing_dummy'), ('Astrid Hofmann', 'ah'), ('Anke Herold', 'Anke Herold_dummy'), ('Christiane Lösch', 'chl'), ('Chris Lademann', 'Chris Lademann_dummy'), ('Ulrich Langer', 'Ulrich Langer_dummy'), ('Thomas Haegeler', 'the'), ('Mathias Wöbking', 'mwö'), ('Von Thomas Steingen', 'ots'), ('Nicole Rathge-Scholz', 'nls'), ('Heiko Stets', 'hs'), ('ter Vehn', 'tv'), ('Jörg ter Vehn', 'ttr'), ('Evelyn ter Vehn', 'lyn'), ('Reinhard Rädler', 'räd'), ('Conny Hanspach', 'Conny Hanspach_dummy'), ('Christoph Springer', 'cs'), ('Christoph Stephan', 'chs'), ('Christian Kunze', 'cku'), ('Jenifer Hochhaus', 'jca'), ('Johannes Angermann', 'jas'), ('Josephine Heinze', 'jhz'), ('Frank Prenzel', 'fpr'), ('Frank Pfeifer', 'fp'), ('Sebastian Fink', 'senf'), ('Catrin Steinbach', 'Catrin Steinbach_dummy'), ('Claus Schimmel', 'Claus Schimmel_dummy'), ('Frank Döring', 'fd'), ('Juliette Guttmann', 'jg'), ('Juliane Groh', 'Juliane Groh_dummy'), ('Heinz Großnick', 'hg'), ('Hanna Gerwig', 'hgw'), ('Nora Ernst', 'noe'), ('Kommentar Thomas Lieb', 'Kommentar Thomas Lieb_dummy'), ('Ines Christ', 'ic'), ('Friederike Ostwald', 'fsw'), ('Kathrin Haase', 'kh'), ('Frank Hörügel', 'fh'), ('Ilka Fischer', 'if'), ('Thomas Lieb', 'thl'), ('Kay Wuerker', 'kw'), ('Dimo Rieß', 'dir'), ('Sebastian Kositz', 'seko'), ('Silke Hoffmann', 'Silke Hoffmann_dummy'), ('Peter Korfmacher', 'kfm'), ('Saskia Grätz', 'saskia'), ('Axel Kaminski', 'ak'), ('Thomas Jentzsch', 'tj'), ('Olaf Majer', 'Olaf Majer_dummy'), ('Mario Jahn', 'maj'), ('Jochen Leimert', 'jol'), ('Michael Graul', 'haeg'), ('Regina Katzer', 'rk'), ('Rainer Küster', 'Rainer Küster_dummy'), ('Roger Dietze', 'red'), ('Heiko Weckbrodt', 'hw'), ('Reinhard Weber', 'Reinhard Weber_dummy'), ('Kerstin Leppich', 'sil'), ('Jane Jannke', 'jaja'), ('Mario Beck', 'mario'), ('Mark Daniel', 'mad'), ('Martin Fischer', 'Martin Fischer_dummy'), ('Robert Berlin', 'rob'), ('Robert Büssow', 'Robert Büssow_dummy'), ('Barbara Stock', 'Barbara Stock_dummy'), ('Bärbel Schumann', 'bs'), ('Arndt Beckert', 'dtb'), ('Daniel Kaiser', 'dk'), ('Dirk Wurzel', 'dw'), ('Dirk Knofe', 'Dirk Knofe_dummy'), ('David Knapp', 'David Knapp_dummy'), ('Benjamin Winkler', 'bw'), ('Tobias Junghannß', 'Tobias Junghannß_dummy'), ('Annett Böhm', 'abö'), ('Tatjana Böhme-Mehner', 'Tatjana Böhme-Mehner_dummy'), ('André Böhmer', 'ab'), ('Ingrid Hildebrandt', 'Ingrid Hildebrandt_dummy'), ('Anne Grimm', 'agri'), ('Clemens Haug', 'chg'), ('Christine Jacob', 'cj'), ('Sabine Kreuz', 'sk'), ('Alexander Laboda', 'ala'), ('Anne Kunze', 'aku'), ('Jeannine Steinbrecher', 'Jeannine Steinbrecher_dummy'), ('Jane Sommer', 'js'), ('Jörg Schurig', 'Jörg Schurig_dummy'), ('Jan Sternberg', 'Jan Sternberg_dummy'), ('Stefan Schilde', 'Stefan Schilde_dummy'), ('Stefan Schramm', 'sts'), ('Peggy Hamfler', 'Peggy Hamfler_dummy'), ('Pia Siemer', 'ps'), ('Petra Mewes', 'pm'), ('Ekkehard Schulreich', 'es'), ('Mathias Schönknecht', 'ms'), ('Inge Engelhardt', 'ie'), ('Ines Eisele', 'Ines Eisele_dummy'), ('Inge-Dore Engelhardt', 'Inge-Dore Engelhardt_dummy'), ('Madeleine Arndt', 'Madeleine Arndt_dummy'), ('Alexander Prautzsch', 'allner'), ('Olaf Büchel', 'obü'), ('Marlies Neumann', 'Marlies Neumann_dummy'), ('Monika Löffler', 'Monika Löffler_dummy'), ('Martin Lange', 'ml'), ('Manuela Engelmann-Bunk', 'almu'), ('Jürgen Kleindienst', 'jkl'), ('Thomas Baumann-Hartwig', 'tbh'), ('Simone Prenzel', 'sp'), ('Felix Kretz', 'kretz'), ('Gabi Liebegall', 'gl'), ('Steffi Robak', 'sro'), ('Markus Bien', 'mb'), ('Mathias Bierende', 'Mathias Bierende_dummy'), ('Kerstin Förster', 'kefö'), ('Björn Meine', 'bm'), ('Hagen Rösner', 'hr'), ('Katharina Schultz', 'katz'), ('Leonie Ebert', 'lieb'), ('Oliver Becker', 'Oliver Becker_dummy'), ('Uwe Hofmann', 'uh'), ('Ulrich Milde', 'Ulrich Milde_dummy'), ('Ute Hirsch', 'Ute Hirsch_dummy'), ('Stephan Hönigschmid', 'pd'), ('Patricia Liebling', 'pl'), ('André Neumann', 'an'), ('Jana Brechlin', 'jb'), ('Steffen Enigk', 'ste'), ('Thomas Lang', 'thlang'), ('Juliane Lange', 'lang'), ('Felix Forberg', 'felix'), ('Florian Theis', 'flo'), ('Florian Reinke', 'fr'), ('Martin Pelzl', 'martin'), ('Sören Schwigon', 'sch'), ('Frank Kastner', 'frank'), ('Rainer Schwurack', 'Rainer Schwurack_dummy'), ('Kerstin Decker', 'rieck'), ('Dieter Taszarek', 'dietze'), ('Julia Tonne', 'jto'), ('Torsten Teichert', 'tonne'), ('Ralf Saupe', 'saupe'), ('Manfred Pfau', 'afp'), ('Olaf Barth', 'olaf'), ('Peter Ruf', 'pr'), ('André Pitz', 'ap'), ('Susanne Weidner', 'swd'), ('Julia Carstens', 'Julia Carstens_dummy'), ('Ralf Hübner', 'ralf'), ('Julia Vollmer', 'jv'), ('René Beuckert', 'reu'), ('Hauke Heuer', 'hh'), ('Horst Hampe', 'Horst Hampe_dummy'), ('Katharina Goldbach', 'kg'), ('Kristin Engel', 'Kristin Engel_dummy'), ('Thomas Kube', 'tk'), ('Tatjana Kulpa', 'Tatjana Kulpa_dummy'), ('Peter Krischunas', 'Peter Krischunas_dummy'), ('Pauline Szyltowski', 'psz'), ('Ines Alekowa', 'ia'), ('Marc Bohländer', 'boh'), ('obü Olaf Büchel', 'obü Olaf Büchel_dummy'), ('Bjarne Johansen-Schmidt', 'bjs'), ('Sarah Englisch', 'she'), ('Wolfgang Sens', 'ws'), ('Steffen Georgi', 'sg'), ('Jochen Schmalz', 'Jochen Schmalz_dummy'), ('Winfried Mahr', 'wim'), ('Katharina Stork', 'kasto'), ('Victoria Graul', 'vg'), ('Paula Drope', 'pad'), ('Lucas Grothe', 'luc'), ('Claudia Carell', 'cc'), ('Cornelia Braun', 'cb'), ('Bastian Fischer', 'bfi'), ('Nathalie Helene Rippich', 'nhr'), ('Martin Kloth', 'kloth'), ('Matthias Klöppel', 'mkl'), ('Maximilian König', 'mk'), ('Gina Apitz', 'gap'), ('Andrea Schrader', 'as'), ('Andrea Schulze', 'Andrea Schulze_dummy'), ('Olaf Krenz', 'okz'), ('Klaus Peschel', 'kul'), ('Simona Block', 'block'), ('Hendrik Schirner', 'Hendrik Schirner_dummy'), ('Hannah Suppa', 'Hannah Suppa_dummy'), ('Ulrike von Leszczynski', 'zys'), ('Nadine Marquardt', 'nqq'), ('Marianne H.-Stars', 'mhs'), ('Stephanie Helm', 'hem'), ('Manuela Engelmann', 'me'), ('Michael Ernst', 'Michael Ernst_dummy'), ('Anton Zirk', 'anzi'), ('Volly Tanner', 'vo'), ('von Christian Neffe', 'von'), ('Christian Neffe', 'cn'), ('Daniel Salpius', 'dei'), ('Von Ditmar Wohlgemuth', 'vm'), ('Valentin Rühlmann', 'Valentin Rühlmann_dummy'), ('Judith Sophie Schilling', 'jps'), ('Christian Wendt', 'cw'), ('Sophie Aschenbrenner', 'soa'), ('Stephanie Jankowski', 'thiko'), ('Thomas Bothe', 'thth'), ('Edgar Lopez', 'elo'), ('Gislinde Redepenning', 'gr'), ('Lisa Neumann', 'lin'), ('Linda Polenz', 'lp'), ('Diemo Wolf', 'ewo'), ('Lotta-Clara Löwener', 'lcl'), ('Anna Flora Schade', 'afs'), ('Eberhard Ulm', 'ebu'), ('Vanessa Gregor', 'vag'), ('Tilman Kortenhaus', 'tik'), ('Uwe Zabell', 'ubl'), ('Ulrich Steinmetzger', 'lmg'), ('Johann-Christoph Landgraf', 'onl'), ('Lars Schmidt', 'lht'), ('Elena Boshkovska', 'eb'), ('Lilly Günthner', 'lg'), ('Lisa Konstantinidis', 'liko'), ('Yvonne Schmidt', 'ys'), ('Josa Mania-Schlegel', 'jmg'), ('Tim Niklas Herholz', 'tnh'), ('Robin Knies', 'rok'), ('Simon Ecker', 'sec'), ('Denise Peikert', 'peik')])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_new.edges"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.438955078Z",
     "start_time": "2023-07-29T13:37:14.436285028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new graph has 681 nodes and 311 edges\n"
     ]
    }
   ],
   "source": [
    "print(f\"new graph has {len(g_new.nodes)} nodes and {len(g_new.edges)} edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.439085648Z",
     "start_time": "2023-07-29T13:37:14.436425028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author_mapping has 311 rows\n",
      "author_mapping has 251 rows\n"
     ]
    }
   ],
   "source": [
    "# transform graph to dataframe author_mapping with columns name and abbreviation\n",
    "author_mapping = pd.DataFrame(columns=[\"name\", \"abbreviation\"], data=g_new.edges)\n",
    "author_mapping = author_mapping.astype(str)\n",
    "\n",
    "print(f\"author_mapping has {author_mapping.shape[0]} rows\")\n",
    "\n",
    "\n",
    "# remove all abbreviations that contain \"dummy\" in their name\n",
    "author_mapping = author_mapping[~author_mapping[\"abbreviation\"].str.contains(\"dummy\")]\n",
    "# print shape\n",
    "print(f\"author_mapping has {author_mapping.shape[0]} rows\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:37:14.439182263Z",
     "start_time": "2023-07-29T13:37:14.436545250Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In the following there are some analyses covering the correctness of the approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m first_article_abbr \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mstrptime(first_article_abbr, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS+00:00\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# check if first_article_abbr is six month ahead of first_article_author\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mfirst_article_abbr\u001B[49m \u001B[38;5;241m<\u001B[39m first_article_author \u001B[38;5;241m-\u001B[39m relativedelta\u001B[38;5;241m.\u001B[39mrelativedelta(months\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauthor: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mauthor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, first_article_author: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_article_author\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, abbreviation: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mabbreviation\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, first_article_abbr: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_article_abbr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     18\u001B[0m     count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[0;32mIn[19], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m first_article_abbr \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mstrptime(first_article_abbr, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS+00:00\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# check if first_article_abbr is six month ahead of first_article_author\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mfirst_article_abbr\u001B[49m \u001B[38;5;241m<\u001B[39m first_article_author \u001B[38;5;241m-\u001B[39m relativedelta\u001B[38;5;241m.\u001B[39mrelativedelta(months\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauthor: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mauthor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, first_article_author: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_article_author\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, abbreviation: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mabbreviation\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, first_article_abbr: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_article_abbr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     18\u001B[0m     count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/232.8660.197/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:880\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    877\u001B[0m             stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m plugin_stop:\n\u001B[0;32m--> 880\u001B[0m     stopped_on_plugin \u001B[38;5;241m=\u001B[39m \u001B[43mplugin_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain_debugger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_cmd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m stop:\n\u001B[1;32m    882\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_line:\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/232.8660.197/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/232.8660.197/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/232.8660.197/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# test if there is an authors that was mapped to an abbreviation that exceeds the authors name writing time by more than 6 months in the time before or after\n",
    "# Note: does not check for authors that exceed abbreviation time. Assumption: an abbreviation can be assigned to an author also later\n",
    "count = 0\n",
    "author_abbreviation_pairs_with_lifespan_difference = []\n",
    "for index, row in author_mapping.iterrows():\n",
    "    author = row[\"name\"]\n",
    "    abbreviation = row[\"abbreviation\"]\n",
    "    author_like = f\"%{json.dumps(author)}%\"\n",
    "    abbr_like = f\"%{json.dumps(abbreviation)}%\"\n",
    "    try:\n",
    "        first_article_author = cur.execute(f\"SELECT MIN(published_at) FROM articles where author_array like ?\", (author_like,)).fetchone()[0]\n",
    "        first_article_abbr = cur.execute(f\"SELECT MIN(published_at) FROM articles where author_array like ?\", (abbr_like,)).fetchone()[0]\n",
    "        first_article_author = datetime.strptime(first_article_author, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        first_article_abbr = datetime.strptime(first_article_abbr, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "        # check if first_article_abbr is six month ahead of first_article_author\n",
    "        if first_article_abbr < first_article_author - relativedelta.relativedelta(months=12):\n",
    "            print(f\"author: {author}, first_article_author: {first_article_author}, abbreviation: {abbreviation}, first_article_abbr: {first_article_abbr}\")\n",
    "            count += 1\n",
    "            author_abbreviation_pairs_with_lifespan_difference.append({\"author\": author, \"abbreviation\": abbreviation})\n",
    "\n",
    "        last_article_author = cur.execute(f\"SELECT MAX(published_at) FROM articles where author_array like ?\", (author_like,)).fetchone()[0]\n",
    "        last_article_abbr = cur.execute(f\"SELECT MAX(published_at) FROM articles where author_array like ?\", (abbr_like,)).fetchone()[0]\n",
    "        last_article_author = datetime.strptime(last_article_author, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        last_article_abbr = datetime.strptime(last_article_abbr, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "        # check if last_article_abbr is six month behind of last_article_author\n",
    "        if last_article_abbr > last_article_author + relativedelta.relativedelta(months=12):\n",
    "            print(f\"author: {author}, last_article_author: {last_article_author}, abbreviation: {abbreviation}, last_article_abbr: {last_article_abbr}\")\n",
    "            count += 1\n",
    "            author_abbreviation_pairs_with_lifespan_difference.append({\"author\": author, \"abbreviation\": abbreviation})\n",
    "    except TypeError:\n",
    "        print(f\"author: {author}, abbreviation: {abbreviation}\")\n",
    "        continue\n",
    "\n",
    "print(f\"there are {count} authors that were mapped to an abbreviation that exceeds the authors name writing time by more than 12 months in the time before or after\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:39:01.115960398Z",
     "start_time": "2023-07-29T13:37:16.668231107Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can conclude that we need a mapping that takes into account the authors' lifespans. Abbreviations can be used for more than one author. Furthermore, we need to penalize abbr-author mappings where the abbreviation has a much longer or shorter lifespan."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further, we notice that there are abbreviations that do not have an associated author. E.g. \"joka\", does not have any good fit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [03:10<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm.tqdm([row for _, row in author_mapping.iterrows()]):\n",
    "    abbr_authors = []\n",
    "    abbr = row[\"abbreviation\"]\n",
    "    mapped_author = row[\"name\"]\n",
    "    abbr_neighbours = list(G.neighbors(abbr))\n",
    "    for author in abbr_neighbours:\n",
    "        author_like = f\"%{json.dumps(author)}%\"\n",
    "        rows = cur.execute('select ar.published_at from articles ar where ar.author_array like ?', (author_like,)).fetchall()\n",
    "        type = \"mapped name\" if author == mapped_author else \"name\"\n",
    "        abbr_authors.extend([{\"author\": author, \"type\": type, \"published_at\": row[0]} for row in rows])\n",
    "\n",
    "    \n",
    "    abbr_like = f\"%{json.dumps(abbr)}%\"\n",
    "    rows = cur.execute('select ar.published_at from articles ar where ar.author_array like ?', (abbr_like,)).fetchall()\n",
    "    abbr_authors.extend([{\"author\": abbr, \"type\": \"abbreviation\", \"published_at\": row[0]} for row in rows])\n",
    "\n",
    "    abbr_authors = pd.DataFrame(columns=[\"author\", \"type\", \"published_at\"], data=abbr_authors)\n",
    "\n",
    "    # aggregate by quarter of the year\n",
    "    abbr_authors['published_at'] = pd.to_datetime(abbr_authors['published_at'])\n",
    "    abbr_authors['quarter'] = abbr_authors['published_at'].dt.quarter\n",
    "    abbr_authors['year'] = abbr_authors['published_at'].dt.year\n",
    "    abbr_authors['year_quarter'] = abbr_authors['year'].astype(str) + \"/\" + abbr_authors['quarter'].astype(str)\n",
    "    #abbr_authors['year_semester'] = abbr_authors['year'].astype(str) + \"/\" + abbr_authors['quarter'].apply(lambda x: 1 if x <= 2 else 2).astype(str)\n",
    "    abbr_authors = abbr_authors.groupby(['year_quarter', 'author', 'type']).count()['published_at'].reset_index()\n",
    "    # rename published at to count\n",
    "    abbr_authors = abbr_authors.rename(columns={\"published_at\": \"count\"})\n",
    "    \n",
    "    # fill year_quarter gaps\n",
    "    year_quarters = abbr_authors['year_quarter'].drop_duplicates()\n",
    "    # get min and max year\n",
    "    min_year = int(min(year_quarters).split(\"/\")[0])\n",
    "    max_year = int(max(year_quarters).split(\"/\")[0])\n",
    "    # get for min_year min quarter and for max_year max quarter\n",
    "    min_quarter = int(min([year_quarter.split(\"/\")[1] for year_quarter in year_quarters if year_quarter.split(\"/\")[0] == str(min_year)]))\n",
    "    max_quarter = int(max([year_quarter.split(\"/\")[1] for year_quarter in year_quarters if year_quarter.split(\"/\")[0] == str(max_year)]))\n",
    "    # create all year_quarters\n",
    "    year_quarters = [str(year) + \"/\" + str(quarter) for year in range(min_year, max_year + 1) for quarter in range(1, 5)]\n",
    "        \n",
    "    # for each author: if there is no entry for a unique combination of 'year_quarter', add it with count np.nan\n",
    "    index = pd.MultiIndex.from_product([year_quarters, abbr_authors['author'].unique()], names=['year_quarter', 'author'])\n",
    "    \n",
    "    # Reindex the DataFrame with the MultiIndex to fill in missing combinations with NaN\n",
    "    abbr_authors = abbr_authors.set_index(['year_quarter', 'author']).reindex(index, fill_value=None).reset_index()\n",
    "    \n",
    "    # set type for each author to first type of that author\n",
    "    abbr_authors['type'] = abbr_authors.groupby('author')['type'].transform('first')\n",
    "    \n",
    "    # sort by year_quarter and type\n",
    "    abbr_authors = abbr_authors.sort_values(by=['year_quarter', 'type'])\n",
    "    \n",
    "    directory = \"author_abbreviation_pairs\"\n",
    "\n",
    "    if {\"author\": mapped_author, \"abbreviation\": abbr} in author_abbreviation_pairs_with_lifespan_difference:\n",
    "        directory = \"author_abbreviation_pairs_with_lifespan_difference\"\n",
    "\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    sns.lineplot(data=abbr_authors, x='year_quarter', y='count', hue='author', style='type', errorbar=None, linewidth=2.5)\n",
    "    # set y title to article count\n",
    "    plt.ylabel(\"article count\")\n",
    "    plt.xlabel(\"year/quarter\")\n",
    "    sns.set(rc={'figure.figsize':(14,10)})\n",
    "    plt.xticks(rotation=-75)\n",
    "    # set ticks to every 4th\n",
    "    plt.xticks(np.arange(0, len(abbr_authors['year_quarter'].unique()), 4))\n",
    "    #plt.tight_layout()\n",
    "    plt.title(f'Article count of abbreviation {abbr}, associated authors and mapped author {mapped_author}')\n",
    "    plt.savefig(f'../reports/figures/{directory}/articles_written_by_abbreviation_{abbr}_and_mapped_author_{\"_\".join(mapped_author.split(\" \"))}_and_associated_authors.png',bbox_inches='tight',dpi=300)\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:12:15.436620388Z",
     "start_time": "2023-07-29T13:09:04.423251492Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mind the fact that seaborn lineplot connects non-neighbouring points. If more correct view is needed, choose scatterplot. See here for further infos: https://stackoverflow.com/questions/52098537/avoid-plotting-missing-values-on-a-line-plot\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Takeaways:\n",
    "* Author entities can have different names (compare Inge Engelhardt and Inge-Dore Engelhardt in \"articles_written_by_abbreviation_ie_and_mapped_author_Inge_Engelhardt_and_associated_authors\"\n",
    "  * an obvious szenario is that the author got married and changed their name\n",
    "* there are only few mappings where the abbreviation and the name share a similar article count distribution \n",
    "  * one good example is: articles_written_by_abbreviation_lyn_and_mapped_author_Evelyn_ter_Vehn_and_associated_authors\n",
    "  * one example for a more or less good similarity is: articles_written_by_abbreviation_hgw_and_mapped_author_Hanna_Gerwig_and_associated_authors\n",
    "  * one example for a match but with close to no similarity is: articles_written_by_abbreviation_krysta_and_mapped_author_Krysta_Brown_and_associated_authors \n",
    "  * a good example for the randomness in using the abbreviation or the name is: articles_written_by_abbreviation_mpu_and_mapped_author_Matthias_Puppe_and_associated_authors\n",
    "  * TODO: Conclusion  \n",
    "\n",
    "Note:\n",
    "If an abbreviation or name has only written articles in one quarter and thus only one data point, it won't get displayed by seaborn\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new graph has 681 nodes and 311 edges\n"
     ]
    }
   ],
   "source": [
    "print(f\"new graph has {len(g_new.nodes)} nodes and {len(g_new.edges)} edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T13:48:39.931711407Z",
     "start_time": "2023-07-29T13:48:39.877049734Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are abbr nodes that were not matched with any author. That's why we have: edges * 2 < nodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbreviation node ast has no edges\n",
      "abbreviation node at has no edges\n",
      "abbreviation node ao has no edges\n",
      "abbreviation node nie has no edges\n",
      "abbreviation node heike has no edges\n",
      "abbreviation node ks has no edges\n",
      "abbreviation node kast has no edges\n",
      "abbreviation node mape has no edges\n",
      "abbreviation node mot has no edges\n",
      "abbreviation node mabe has no edges\n",
      "abbreviation node mato has no edges\n",
      "abbreviation node beck has no edges\n",
      "abbreviation node bos has no edges\n",
      "abbreviation node seb has no edges\n",
      "abbreviation node fb has no edges\n",
      "abbreviation node brown has no edges\n",
      "abbreviation node mayer has no edges\n",
      "abbreviation node may has no edges\n",
      "abbreviation node mas has no edges\n",
      "abbreviation node ts has no edges\n",
      "abbreviation node meine has no edges\n",
      "abbreviation node thomas has no edges\n",
      "abbreviation node th has no edges\n",
      "abbreviation node ter vehn has no edges\n",
      "abbreviation node rare has no edges\n",
      "abbreviation node cha has no edges\n",
      "abbreviation node ja has no edges\n",
      "abbreviation node sf has no edges\n",
      "abbreviation node döring has no edges\n",
      "abbreviation node nag has no edges\n",
      "abbreviation node fw has no edges\n",
      "abbreviation node kha has no edges\n",
      "abbreviation node fel has no edges\n",
      "abbreviation node isc has no edges\n",
      "abbreviation node ski has no edges\n",
      "abbreviation node grätz has no edges\n",
      "abbreviation node sag has no edges\n",
      "abbreviation node rd has no edges\n",
      "abbreviation node roger has no edges\n",
      "abbreviation node wurzel has no edges\n",
      "abbreviation node kreuz has no edges\n",
      "abbreviation node sabine has no edges\n",
      "abbreviation node kunze has no edges\n",
      "abbreviation node büchel has no edges\n",
      "abbreviation node sie has no edges\n",
      "abbreviation node s robak has no edges\n",
      "abbreviation node iro has no edges\n",
      "abbreviation node björn has no edges\n",
      "abbreviation node rösner has no edges\n",
      "abbreviation node haase has no edges\n",
      "abbreviation node hagen has no edges\n",
      "abbreviation node epd has no edges\n",
      "abbreviation node pb has no edges\n",
      "abbreviation node pat has no edges\n",
      "abbreviation node sei has no edges\n",
      "abbreviation node pelzl has no edges\n",
      "abbreviation node julia has no edges\n",
      "abbreviation node nq has no edges\n",
      "abbreviation node s helm has no edges\n"
     ]
    }
   ],
   "source": [
    "# test that only abbrs are not in the matches nodes\n",
    "for node in g_new.nodes:\n",
    "    if g_new.degree(node) == 0 and node in author_list:\n",
    "        print(f\"author node {node} has no edges\")\n",
    "    elif g_new.degree(node) == 0 and node in abbr_list:\n",
    "        print(f\"abbreviation node {node} has no edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T11:03:34.081970792Z",
     "start_time": "2023-07-29T11:03:34.064782244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new neighbors of old abbr ast node neighbors Andreas Tappert are ['art']\n",
      "new neighbors of old abbr at node neighbors Andreas Tappert are ['art']\n",
      "new neighbors of old abbr ao node neighbors Antje Henselin-Rudolph are ['ahr']\n",
      "new neighbors of old abbr ao node neighbors Alexander Laboda are ['ala']\n",
      "new neighbors of old abbr nie node neighbors Nico Fliegner are ['nf']\n",
      "new neighbors of old abbr heike node neighbors Heike Liesaus are ['hl']\n",
      "new neighbors of old abbr ks node neighbors Klaus Staeubert are ['kas']\n",
      "new neighbors of old abbr ks node neighbors Katharina Stork are ['kasto']\n",
      "new neighbors of old abbr kast node neighbors Klaus Staeubert are ['kas']\n",
      "new neighbors of old abbr kast node neighbors Katharina Stork are ['kasto']\n",
      "new neighbors of old abbr mape node neighbors Matthias Puppe are ['mpu']\n",
      "new neighbors of old abbr mot node neighbors Matthias Roth are ['mro']\n",
      "new neighbors of old abbr mabe node neighbors Mathias Orbeck are ['mo']\n",
      "new neighbors of old abbr mabe node neighbors Mario Beck are ['mario']\n",
      "new neighbors of old abbr mato node neighbors Mathias Orbeck are ['mo']\n",
      "new neighbors of old abbr beck node neighbors Mathias Orbeck are ['mo']\n",
      "new neighbors of old abbr beck node neighbors Mario Beck are ['mario']\n",
      "new neighbors of old abbr bos node neighbors Steffen Brost are ['sb']\n",
      "new neighbors of old abbr seb node neighbors Steffen Brost are ['sb']\n",
      "new neighbors of old abbr fb node neighbors Steffen Brost are ['sb']\n",
      "new neighbors of old abbr brown node neighbors Krysta Brown are ['krysta']\n",
      "new neighbors of old abbr mayer node neighbors Thomas Mayer are ['tom']\n",
      "new neighbors of old abbr mayer node neighbors Michael Strohmeyer are ['m strohmeyer']\n",
      "new neighbors of old abbr may node neighbors Maria Keybe are ['mey']\n",
      "new neighbors of old abbr may node neighbors Michael Strohmeyer are ['m strohmeyer']\n",
      "new neighbors of old abbr mas node neighbors Michael Strohmeyer are ['m strohmeyer']\n",
      "new neighbors of old abbr mas node neighbors Mathias Schönknecht are ['ms']\n",
      "new neighbors of old abbr ts node neighbors Thomas Steingen are ['totei']\n",
      "new neighbors of old abbr ts node neighbors Thomas Sparrer are ['tsa']\n",
      "new neighbors of old abbr meine node neighbors Thomas Steingen are ['totei']\n",
      "new neighbors of old abbr meine node neighbors Björn Meine are ['bm']\n",
      "new neighbors of old abbr thomas node neighbors Thomas Sparrer are ['tsa']\n",
      "new neighbors of old abbr th node neighbors Thomas Haegeler are ['the']\n",
      "new neighbors of old abbr ter vehn node neighbors Jörg ter Vehn are ['ttr']\n",
      "new neighbors of old abbr rare node neighbors Reinhard Rädler are ['räd']\n",
      "new neighbors of old abbr cha node neighbors Christian Kunze are ['cku']\n",
      "new neighbors of old abbr cha node neighbors Clemens Haug are ['chg']\n",
      "new neighbors of old abbr cha node neighbors Christine Jacob are ['cj']\n",
      "new neighbors of old abbr ja node neighbors Johannes Angermann are ['jas']\n",
      "new neighbors of old abbr sf node neighbors Sebastian Fink are ['senf']\n",
      "new neighbors of old abbr döring node neighbors Frank Döring are ['fd']\n",
      "new neighbors of old abbr nag node neighbors Hanna Gerwig are ['hgw']\n",
      "new neighbors of old abbr nag node neighbors Vanessa Gregor are ['vag']\n",
      "new neighbors of old abbr fw node neighbors Friederike Ostwald are ['fsw']\n",
      "new neighbors of old abbr kha node neighbors Kathrin Haase are ['kh']\n",
      "new neighbors of old abbr fel node neighbors Frank Hörügel are ['fh']\n",
      "new neighbors of old abbr isc node neighbors Ilka Fischer are ['if']\n",
      "new neighbors of old abbr ski node neighbors Sebastian Kositz are ['seko']\n",
      "new neighbors of old abbr ski node neighbors Saskia Grätz are ['saskia']\n",
      "new neighbors of old abbr ski node neighbors Axel Kaminski are ['ak']\n",
      "new neighbors of old abbr grätz node neighbors Saskia Grätz are ['saskia']\n",
      "new neighbors of old abbr sag node neighbors Saskia Grätz are ['saskia']\n",
      "new neighbors of old abbr rd node neighbors Roger Dietze are ['red']\n",
      "new neighbors of old abbr roger node neighbors Roger Dietze are ['red']\n",
      "new neighbors of old abbr wurzel node neighbors Dirk Wurzel are ['dw']\n",
      "new neighbors of old abbr kreuz node neighbors Sabine Kreuz are ['sk']\n",
      "new neighbors of old abbr sabine node neighbors Sabine Kreuz are ['sk']\n",
      "new neighbors of old abbr kunze node neighbors Anne Kunze are ['aku']\n",
      "new neighbors of old abbr büchel node neighbors Olaf Büchel are ['obü']\n",
      "new neighbors of old abbr sie node neighbors Simone Prenzel are ['sp']\n",
      "new neighbors of old abbr s robak node neighbors Steffi Robak are ['sro']\n",
      "new neighbors of old abbr iro node neighbors Steffi Robak are ['sro']\n",
      "new neighbors of old abbr björn node neighbors Björn Meine are ['bm']\n",
      "new neighbors of old abbr rösner node neighbors Hagen Rösner are ['hr']\n",
      "new neighbors of old abbr haase node neighbors Hagen Rösner are ['hr']\n",
      "new neighbors of old abbr hagen node neighbors Hagen Rösner are ['hr']\n",
      "new neighbors of old abbr epd node neighbors Stephan Hönigschmid are ['pd']\n",
      "new neighbors of old abbr pb node neighbors Patricia Liebling are ['pl']\n",
      "new neighbors of old abbr pb node neighbors Sophie Aschenbrenner are ['soa']\n",
      "new neighbors of old abbr pat node neighbors Patricia Liebling are ['pl']\n",
      "new neighbors of old abbr pat node neighbors Pauline Szyltowski are ['psz']\n",
      "new neighbors of old abbr sei node neighbors Steffen Enigk are ['ste']\n",
      "new neighbors of old abbr sei node neighbors Sarah Englisch are ['she']\n",
      "new neighbors of old abbr pelzl node neighbors Martin Pelzl are ['martin']\n",
      "new neighbors of old abbr julia node neighbors Julia Tonne are ['jto']\n",
      "new neighbors of old abbr nq node neighbors Nadine Marquardt are ['nqq']\n",
      "new neighbors of old abbr s helm node neighbors Stephanie Helm are ['hem']\n"
     ]
    }
   ],
   "source": [
    "# list the abbreviations that were connected to the author that the edges with zero edges were pointing to\n",
    "# so we can e.g. check if we need to enable multiple abbreviations for the same author\n",
    "for node in g_new.nodes:\n",
    "    if g_new.degree(node) == 0:\n",
    "        # check the authors of the old graph that were pointing to this abbreviation\n",
    "        old_neighbors = G.neighbors(node)\n",
    "        for old_neighbor in old_neighbors:\n",
    "            print(f\"new neighbors of old abbr {node} node neighbors {old_neighbor} are {list(g_new.neighbors(old_neighbor))}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T11:04:11.596623737Z",
     "start_time": "2023-07-29T11:04:11.548163101Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this we do see that some authors have several abbreviations\n",
    "For example: krysta brown has probably two abbreviations: \"krysta\" and \"brown\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 abbreviations were matched\n",
      "There are 59 abbreviations that were not matched\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(len(g_new.edges))} abbreviations were matched\")\n",
    "print(f\"There are {len(g_new.nodes) - (len(g_new.edges) * 2)} abbreviations that were not matched\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T11:04:48.077217486Z",
     "start_time": "2023-07-29T11:04:48.034381717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ast', 'at', 'ao', 'nie', 'heike', 'ks', 'kast', 'mape', 'mot', 'mabe', 'mato', 'beck', 'bos', 'seb', 'fb', 'brown', 'mayer', 'may', 'mas', 'ts', 'meine', 'thomas', 'th', 'ter vehn', 'rare', 'cha', 'ja', 'sf', 'döring', 'nag', 'fw', 'kha', 'fel', 'isc', 'ski', 'grätz', 'sag', 'rd', 'roger', 'wurzel', 'kreuz', 'sabine', 'kunze', 'büchel', 'sie', 's robak', 'iro', 'björn', 'rösner', 'haase', 'hagen', 'epd', 'pb', 'pat', 'sei', 'pelzl', 'julia', 'nq', 's helm']\n"
     ]
    }
   ],
   "source": [
    "# print not matched abbreviations\n",
    "print([node for node in g_new.nodes if g_new.degree(node) == 0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T11:05:07.209028344Z",
     "start_time": "2023-07-29T11:05:07.164090017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 abbreviations have only one edge in the old graph\n",
      "['ao', 'ks', 'kast', 'mabe', 'beck', 'mayer', 'may', 'mas', 'ts', 'meine', 'cha', 'nag', 'ski', 'pb', 'pat', 'sei']\n"
     ]
    }
   ],
   "source": [
    "# test if these abbreviations have only one edge in the old graph. If so, we can append them to that author.\n",
    "# assumes that the names got assigned a more fitting abbreviation but these here do also belong to that name\n",
    "unmatched_abbrs_with_only_one_edge = [node for node in g_new.nodes if g_new.degree(node) == 0 and len(list(G.neighbors(node))) == 1]\n",
    "print(f\"{len(unmatched_abbrs_with_only_one_edge)} abbreviations have only one edge in the old graph\")\n",
    "\n",
    "# list remaining abbreviations\n",
    "remaining_abbrs = [node for node in g_new.nodes if g_new.degree(node) == 0 and len(list(G.neighbors(node))) > 1]\n",
    "print(remaining_abbrs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T11:05:31.027076685Z",
     "start_time": "2023-07-29T11:05:31.021420309Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We conclude, that most of the unmatched abbreviations were only connected to one author originally. That means that we can append them to that author because we know now that authors can have multiple abbreviations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lvz_venv",
   "language": "python",
   "display_name": "lvz_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
