{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:20:56.933635269Z",
     "start_time": "2024-01-24T22:20:56.839140576Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from dateutil import relativedelta\n",
    "from datetime import datetime\n",
    "import tqdm\n",
    "from src.models.MatchingType import MatchingType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "con = sqlite3.connect('../data/interim/articles_with_author_mapping.db')\n",
    "cur = con.cursor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:20:58.825555339Z",
     "start_time": "2024-01-24T22:20:58.812703504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_abbreviations_with_names():\n",
    "    cur.execute(\"select id, name, abbreviation, matching_certainty from unmapped_authors where matching_type = ? or matching_type = ?\", (MatchingType.FUZZY_MATCH.name, MatchingType.DIRECT_MATCH.name))\n",
    "    rows = cur.fetchall()\n",
    "    authors = pd.DataFrame(columns=[\"id\", \"name\", \"abbreviation\", \"certainty\"], data=rows)\n",
    "    authors.set_index(\"id\", inplace=True)\n",
    "    return authors\n",
    "\n",
    "authors = get_abbreviations_with_names()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:20:59.542925860Z",
     "start_time": "2024-01-24T22:20:59.415186086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# set certainty of a row to the average certainty over all rows with same name and abbreviation, ignore nan values\n",
    "mean_certainty = authors.groupby([\"name\", \"abbreviation\"])[\"certainty\"].transform(lambda x: np.nanmean(x))\n",
    "authors[\"certainty\"] = mean_certainty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:00.738022815Z",
     "start_time": "2024-01-24T22:21:00.680377311Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "authors[\"name_pointing_to_abbreviation_count\"] = authors.groupby([\"name\", \"abbreviation\"])[\"name\"].transform(\"count\")\n",
    "authors[\"abbreviation_pointing_to_name_count\"] = authors.groupby([\"name\", \"abbreviation\"])[\"abbreviation\"].transform(\"count\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:01.234283723Z",
     "start_time": "2024-01-24T22:21:01.206184677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# drop duplicates based on name, abbreviation, certainty. I can drop them because ..._count saved the count\n",
    "authors.drop_duplicates(subset=[\"name\", \"abbreviation\", \"certainty\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:01.640237582Z",
     "start_time": "2024-01-24T22:21:01.618790390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# set the share that the name has of all names that point to that abbreviation\n",
    "authors_with_name_pointing_to_abbreviation_sum =  authors.groupby([\"abbreviation\"]).agg(names_pointing_to_abbreviation_sum=(\"name_pointing_to_abbreviation_count\", \"sum\")).reset_index()\n",
    "authors = pd.merge(authors, authors_with_name_pointing_to_abbreviation_sum, on=\"abbreviation\")\n",
    "authors[\"name_pointing_to_abbreviation_share\"] = authors[\"name_pointing_to_abbreviation_count\"] / authors[\"names_pointing_to_abbreviation_sum\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:02.137184650Z",
     "start_time": "2024-01-24T22:21:02.117125637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# set the share that the abbreviation has of all abbreviations that point to that name\n",
    "authors_with_abbreviation_pointing_to_name_sum = authors.groupby([\"name\"]).agg(abbreviations_pointing_to_name_sum=(\"abbreviation_pointing_to_name_count\", \"sum\")).reset_index()\n",
    "authors = pd.merge(authors, authors_with_abbreviation_pointing_to_name_sum, on=\"name\")\n",
    "authors[\"abbreviation_pointing_to_name_share\"] = authors[\"abbreviation_pointing_to_name_count\"] / authors[\"abbreviations_pointing_to_name_sum\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:02.524474361Z",
     "start_time": "2024-01-24T22:21:02.511911138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# calculate a final score for the weighted edge between name and abbreviation\n",
    "authors[\"score\"] = authors[\"certainty\"] + authors[\"name_pointing_to_abbreviation_share\"] + authors[\"abbreviation_pointing_to_name_share\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:02.991685258Z",
     "start_time": "2024-01-24T22:21:02.980174181Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# reduce the problem space to a bipartite graph, assigning all (name, abbreviation) pairs that are not connected to the graph as final/solved\n",
    "# add pairs to final mapping where abbreviation_pointing_to_name_count == 1 or name_pointing_to_abbreviation_count == 1 and remove those from the authors \n",
    "#one_to_one_mappings = authors[(authors[\"abbreviations_pointing_to_name_sum\"] == 1) & (authors[\"names_pointing_to_abbreviation_sum\"] == 1)]\n",
    "#final_mapping = pd.concat([final_mapping, one_to_one_mappings[[\"name\", \"abbreviation\"]]], ignore_index=True)\n",
    "\n",
    "#authors = authors[(authors[\"abbreviations_pointing_to_name_sum\"] != 1) | (authors[\"names_pointing_to_abbreviation_sum\"] != 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:03.452361786Z",
     "start_time": "2024-01-24T22:21:03.439299031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# remove self referencing nodes\n",
    "authors = authors[authors[\"name\"].str.lower() != authors[\"abbreviation\"].str.lower()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:04.482895899Z",
     "start_time": "2024-01-24T22:21:04.472729790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.clear()\n",
    "author_list = list(authors[\"name\"].unique())\n",
    "abbr_list = list(authors[authors[\"name\"].isin(author_list)][\"abbreviation\"].unique())\n",
    "G.add_nodes_from(author_list, bipartite=0)\n",
    "G.add_nodes_from(abbr_list, bipartite=1)\n",
    "dummy_nodes = [f\"{name}_dummy\" for name in author_list]\n",
    "G.add_nodes_from(dummy_nodes, bipartite=1)\n",
    "\n",
    "edges = []\n",
    "for index, row in authors[authors[\"name\"].isin(author_list) & authors[\"abbreviation\"].isin(abbr_list)].iterrows():\n",
    "    G.add_edges_from([(row[\"name\"], row[\"abbreviation\"])], weight=round(row[\"score\"],2) * -1)\n",
    "\n",
    "for name in author_list:\n",
    "    G.add_edges_from([(name, f\"{name}_dummy\")], weight=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:06.165220848Z",
     "start_time": "2024-01-24T22:21:06.124797758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "new_edges = nx.bipartite.minimum_weight_full_matching(G, top_nodes=list(authors[\"name\"].unique()), weight=\"weight\")\n",
    "g_new = nx.Graph()\n",
    "g_new.clear()\n",
    "g_new.add_nodes_from(author_list, bipartite=0)\n",
    "g_new.add_nodes_from(abbr_list, bipartite=1)\n",
    "g_new.add_edges_from(new_edges.items())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:06.985569866Z",
     "start_time": "2024-01-24T22:21:06.940187476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "EdgeView([('Kai-Uwe Brandt', 'kub'), ('Nadja Topfstedt', 'jap'), ('Andreas Tappert', 'art'), ('Annett Riedel', 'ar'), ('Angelika Raulien', 'Angelika Raulien_dummy'), ('Andrea Richter', 'Andrea Richter_dummy'), ('Antje Henselin-Rudolph', 'ahr'), ('Heike Liesaus', 'Heike Liesaus_dummy'), ('Juliane Streich', 'Juliane Streich_dummy'), ('Janina Fleischer', 'jaf'), ('Lisa Berins', 'Lisa Berins_dummy'), ('Lisa Schliep', 'lis'), ('Nico Fliegner', 'nf'), ('Frank Pfütze', 'pfü'), ('Werner Kopfmüller', 'Werner Kopfmüller_dummy'), ('Kendra Reinhardt', 'Kendra Reinhardt_dummy'), ('Karoline Maria Keybe', 'Karoline Maria Keybe_dummy'), ('Karin Rieck', 'karin'), ('Karin Tamcke', 'Karin Tamcke_dummy'), ('Klaus Staeubert', 'ks'), ('Kay Würker', 'ka'), ('Kathrin Kabelitz', 'Kathrin Kabelitz_dummy'), ('Kai Kollenberg', 'kol'), ('Nikos Natsidis', 'nn'), ('Matthias Puppe', 'mpu'), ('Robert Nößler', 'nöß'), ('Ditmar Wohlgemuth', 'Ditmar Wohlgemuth_dummy'), ('Claudia Carell-Domröse', 'Claudia Carell-Domröse_dummy'), ('Dominik Bath', 'Dominik Bath_dummy'), ('Dominic Welters', 'dom'), ('Michael Dick', 'midi'), ('Matthias Roth', 'mro'), ('Manuel Niemann', 'mi'), ('Mathias Orbeck', 'mo'), ('Robin Seidler', 'Robin Seidler_dummy'), ('Birgit Schöppenthau', 'bis'), ('Bastian Schröder', 'Bastian Schröder_dummy'), ('Christin Grödel', 'cgr'), ('Christine Gräfe', 'cg'), ('Steffen Brost', 'bro'), ('Guido Schäfer', 'gs'), ('Kathleen Retzar', 'kr'), ('Stephan Lohse', 'sl'), ('Simone Liss', 'Simone Liss_dummy'), ('Holger Günther', 'hog'), ('Stefan Banitz', 'stb'), ('Jens Rosenkranz', 'joka'), ('Andreas Dunte', 'Andreas Dunte_dummy'), ('Andreas Debski', 'ade'), ('Jens Rometsch', 'joh'), ('Jörg Reuter', 'jr'), ('Michael Strohmeyer', 'mey'), ('Frank Schmidt', 'fs'), ('Frauke Sievers', 'Frauke Sievers_dummy'), ('Frank Schober', 'Frank Schober_dummy'), ('Uwe Köster', 'ukö'), ('Julia Wick', 'Julia Wick_dummy'), ('Jörg Wolf', 'jw'), ('Thomas Steingen', 'ts'), ('Thomas Sparrer', 'tsa'), ('Alexander Bley', 'bly'), ('Ulrike Witt', 'uw'), ('Reik Anton', 'ra'), ('Christiane Lösch', 'chl'), ('Ulrich Langer', 'Ulrich Langer_dummy'), ('Roland Heinrich', 'rohe'), ('Roland Herold', 'Roland Herold_dummy'), ('Thomas Haegeler', 'the'), ('Mathias Wöbking', 'mwö'), ('ter Vehn', 'tv'), ('Jörg ter Vehn', 'ttr'), ('Evelyn ter Vehn', 'lyn'), ('Jenifer Hochhaus', 'jca'), ('Johannes Angermann', 'jas'), ('Josephine Heinze', 'jhz'), ('Frank Pfeifer', 'fp'), ('Frank Prenzel', 'Frank Prenzel_dummy'), ('Catrin Steinbach', 'Catrin Steinbach_dummy'), ('Christoph Springer', 'cs'), ('Christian Kunze', 'Christian Kunze_dummy'), ('Frank Döring', 'fd'), ('Nora Ernst', 'noe'), ('Ines Christ', 'ic'), ('Kathrin Haase', 'kh'), ('Ilka Fischer', 'if'), ('Thomas Lieb', 'thl'), ('Silke Hoffmann', 'Silke Hoffmann_dummy'), ('Peter Korfmacher', 'kfm'), ('Saskia Grätz', 'saskia'), ('Axel Kaminski', 'ski'), ('Sebastian Kositz', 'sk'), ('Michael Graul', 'haeg'), ('Hanna Gerwig', 'hgw'), ('Regina Katzer', 'rk'), ('Rainer Küster', 'Rainer Küster_dummy'), ('Roger Dietze', 'roger'), ('Reinhard Rädler', 'red'), ('Mario Beck', 'mario'), ('Michael Frömmert', 'mf'), ('Manfred Hainich', 'maf'), ('Thomas Fritz', 'Thomas Fritz_dummy'), ('Robert Berlin', 'rob'), ('Robert Büssow', 'Robert Büssow_dummy'), ('Benjamin Winkler', 'bw'), ('Annett Böhm', 'Annett Böhm_dummy'), ('Tatjana Böhme-Mehner', 'Tatjana Böhme-Mehner_dummy'), ('André Böhmer', 'abö'), ('Dominik Brüggemann', 'dbr'), ('Ingrid Hildebrandt', 'Ingrid Hildebrandt_dummy'), ('Anne Grimm', 'agri'), ('Sabine Kreuz', 'sabine'), ('Anne Kunze', 'aku'), ('Christine Jacob', 'cj'), ('Peggy Hamfler', 'Peggy Hamfler_dummy'), ('Pia Siemer', 'ps'), ('Petra Mewes', 'pm'), ('Ekkehard Schulreich', 'es'), ('Inge Engelhardt', 'ie'), ('Alexander Prautzsch', 'allner'), ('Jürgen Kleindienst', 'jkl'), ('Simone Prenzel', 'sp'), ('Olaf Büchel', 'obü'), ('Steffi Robak', 'sro'), ('Björn Meine', 'bm'), ('Dirk Wurzel', 'diw'), ('Alexander Laboda', 'ala'), ('Uwe Hofmann', 'uh'), ('Ulrich Milde', 'Ulrich Milde_dummy'), ('Ulf Heise', 'Ulf Heise_dummy'), ('André Neumann', 'an'), ('Clemens Haug', 'chg'), ('Thomas Lang', 'thlang'), ('Juliane Lange', 'lang'), ('Florian Theis', 'flo'), ('Florian Reinke', 'fr'), ('Frank Hörügel', 'frank'), ('Kerstin Decker', 'rieck'), ('Dieter Taszarek', 'dietze'), ('André Pitz', 'ap'), ('Andreas Weidlich', 'Andreas Weidlich_dummy'), ('Susanne Weidner', 'swd'), ('Julia Vollmer', 'jv'), ('Peter Krischunas', 'Peter Krischunas_dummy'), ('Pauline Szyltowski', 'psz'), ('Marc Bohländer', 'boh'), ('Elena Boshkovska', 'Elena Boshkovska_dummy'), ('Steffen Georgi', 'sg'), ('Melanie Steitz', 'mes'), ('Mathias Schönknecht', 'mhs'), ('Katharina Stork', 'kasto'), ('Lucas Grothe', 'luc'), ('Claudia Carell', 'cc'), ('Friederike Ostwald', 'fsw'), ('Julia Tonne', 'jto'), ('Sebastian Fink', 'Sebastian Fink_dummy'), ('Bastian Fischer', 'bfi'), ('Nathalie Helene Rippich', 'nhr'), ('Gina Apitz', 'gap'), ('Andrea Schrader', 'as'), ('Andrea Schulze', 'Andrea Schulze_dummy'), ('Olaf Krenz', 'okz'), ('Heiko Stets', 'hs'), ('Hannah Suppa', 'Hannah Suppa_dummy'), ('Nadine Marquardt', 'nqq'), ('Stephanie Helm', 'hem'), ('Anton Zirk', 'anzi'), ('Christian Neffe', 'cn'), ('Sophie Aschenbrenner', 'soa'), ('Stephanie Jankowski', 'thiko'), ('Thomas Bothe', 'thth'), ('Linda Polenz', 'lin'), ('Patricia Liebling', 'pb'), ('Lotta-Clara Löwener', 'lcl'), ('Anna Flora Schade', 'afs'), ('Manuela Engelmann-Bunk', 'almu'), ('René Beuckert', 'ebu'), ('Vanessa Gregor', 'vag'), ('Ulrich Steinmetzger', 'lmg'), ('Lilly Günthner', 'lg'), ('Yvonne Schmidt', 'ys'), ('Tim Niklas Herholz', 'tnh'), ('Simon Ecker', 'sec')])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_new.edges"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:09.258854331Z",
     "start_time": "2024-01-24T22:21:09.252517415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new graph has 385 nodes and 182 edges\n"
     ]
    }
   ],
   "source": [
    "print(f\"new graph has {len(g_new.nodes)} nodes and {len(g_new.edges)} edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:13.225080649Z",
     "start_time": "2024-01-24T22:21:13.201422339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author_mapping has 182 rows\n",
      "author_mapping has 141 rows\n"
     ]
    }
   ],
   "source": [
    "# transform graph to dataframe author_mapping with columns name and abbreviation\n",
    "author_mapping = pd.DataFrame(columns=[\"name\", \"abbreviation\"], data=g_new.edges)\n",
    "author_mapping = author_mapping.astype(str)\n",
    "\n",
    "print(f\"author_mapping has {author_mapping.shape[0]} rows\")\n",
    "\n",
    "\n",
    "# remove all abbreviations that contain \"dummy\" in their name\n",
    "author_mapping = author_mapping[~author_mapping[\"abbreviation\"].str.contains(\"dummy\")]\n",
    "# print shape\n",
    "print(f\"author_mapping has {author_mapping.shape[0]} rows\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:21:51.158947614Z",
     "start_time": "2024-01-24T22:21:51.111656142Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In the following there are some analyses covering the correctness of the approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author: Lisa Schliep, first_article_author: 2015-05-14 21:59:00, abbreviation: lis, first_article_abbr: 2010-01-07 15:35:14\n",
      "author: Manuel Niemann, first_article_author: 2016-06-30 07:10:00, abbreviation: mi, first_article_abbr: 2010-01-27 17:55:42\n",
      "author: Christine Gräfe, last_article_author: 2013-07-21 13:37:00, abbreviation: cg, last_article_abbr: 2021-07-18 08:30:06\n",
      "author: Kathleen Retzar, first_article_author: 2020-10-02 12:36:18, abbreviation: kr, first_article_abbr: 2010-02-14 13:54:25\n",
      "author: Jörg Reuter, last_article_author: 2020-04-07 07:12:00, abbreviation: jr, last_article_abbr: 2021-12-13 18:56:42\n",
      "author: Jörg Wolf, first_article_author: 2011-05-03 19:14:21, abbreviation: jw, first_article_abbr: 2010-04-01 08:07:16\n",
      "author: Thomas Steingen, last_article_author: 2018-04-20 08:00:00, abbreviation: ts, last_article_abbr: 2021-12-28 17:01:00\n",
      "author: Christiane Lösch, last_article_author: 2016-10-06 07:56:00, abbreviation: chl, last_article_abbr: 2017-10-06 10:16:00\n",
      "author: ter Vehn, last_article_author: 2017-01-18 17:58:00, abbreviation: tv, last_article_abbr: 2021-12-22 16:01:00\n",
      "author: Michael Graul, last_article_author: 2011-03-10 12:00:31, abbreviation: haeg, last_article_abbr: 2021-10-29 15:28:00\n",
      "author: Michael Frömmert, last_article_author: 2016-04-17 20:51:00, abbreviation: mf, last_article_abbr: 2018-06-28 10:55:16\n",
      "author: Manfred Hainich, first_article_author: 2011-09-06 08:48:10, abbreviation: maf, first_article_abbr: 2010-01-04 15:25:21\n",
      "author: Pia Siemer, first_article_author: 2015-07-14 17:03:00, abbreviation: ps, first_article_abbr: 2013-10-24 17:31:00\n",
      "author: Petra Mewes, first_article_author: 2020-01-18 12:17:19, abbreviation: pm, first_article_abbr: 2011-08-01 13:08:41\n",
      "author: Inge Engelhardt, last_article_author: 2020-04-21 17:51:00, abbreviation: ie, last_article_abbr: 2021-12-16 17:24:00\n",
      "author: Florian Theis, last_article_author: 2013-10-07 18:17:00, abbreviation: flo, last_article_abbr: 2021-12-30 19:01:00\n",
      "author: Friederike Ostwald, first_article_author: 2013-03-25 07:56:00, abbreviation: fsw, first_article_abbr: 2010-08-22 11:12:21\n",
      "author: Stephanie Jankowski, last_article_author: 2017-05-25 14:35:00, abbreviation: thiko, last_article_abbr: 2019-07-15 21:23:00\n",
      "there are 18 authors that were mapped to an abbreviation that exceeds the authors name writing time by more than 12 months in the time before or after\n"
     ]
    }
   ],
   "source": [
    "# test if there is an authors that was mapped to an abbreviation that exceeds the authors name writing time by more than 6 months in the time before or after\n",
    "# Note: does not check for authors that exceed abbreviation time. Assumption: an abbreviation can be assigned to an author also later\n",
    "count = 0\n",
    "author_abbreviation_pairs_with_lifespan_difference = []\n",
    "for index, row in author_mapping.iterrows():\n",
    "    author = row[\"name\"]\n",
    "    abbreviation = row[\"abbreviation\"]\n",
    "    author_like = f\"%{json.dumps(author)}%\"\n",
    "    abbr_like = f\"%{json.dumps(abbreviation)}%\"\n",
    "    try:\n",
    "        first_article_author = cur.execute(f\"SELECT MIN(published_at) FROM articles where author_array like ?\", (author_like,)).fetchone()[0]\n",
    "        first_article_abbr = cur.execute(f\"SELECT MIN(published_at) FROM articles where author_array like ?\", (abbr_like,)).fetchone()[0]\n",
    "        first_article_author = datetime.strptime(first_article_author, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        first_article_abbr = datetime.strptime(first_article_abbr, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "        # check if first_article_abbr is six month ahead of first_article_author\n",
    "        if first_article_abbr < first_article_author - relativedelta.relativedelta(months=12):\n",
    "            print(f\"author: {author}, first_article_author: {first_article_author}, abbreviation: {abbreviation}, first_article_abbr: {first_article_abbr}\")\n",
    "            count += 1\n",
    "            author_abbreviation_pairs_with_lifespan_difference.append({\"author\": author, \"abbreviation\": abbreviation})\n",
    "\n",
    "        last_article_author = cur.execute(f\"SELECT MAX(published_at) FROM articles where author_array like ?\", (author_like,)).fetchone()[0]\n",
    "        last_article_abbr = cur.execute(f\"SELECT MAX(published_at) FROM articles where author_array like ?\", (abbr_like,)).fetchone()[0]\n",
    "        last_article_author = datetime.strptime(last_article_author, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        last_article_abbr = datetime.strptime(last_article_abbr, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "        # check if last_article_abbr is six month behind of last_article_author\n",
    "        if last_article_abbr > last_article_author + relativedelta.relativedelta(months=12):\n",
    "            print(f\"author: {author}, last_article_author: {last_article_author}, abbreviation: {abbreviation}, last_article_abbr: {last_article_abbr}\")\n",
    "            count += 1\n",
    "            author_abbreviation_pairs_with_lifespan_difference.append({\"author\": author, \"abbreviation\": abbreviation})\n",
    "    except TypeError:\n",
    "        print(f\"author: {author}, abbreviation: {abbreviation}\")\n",
    "        continue\n",
    "\n",
    "print(f\"there are {count} authors that were mapped to an abbreviation that exceeds the authors name writing time by more than 12 months in the time before or after\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T22:29:05.994800573Z",
     "start_time": "2024-01-24T22:22:04.901078275Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can conclude that we need a mapping that takes into account the authors' lifespans. Abbreviations can be used for more than one author. Furthermore, we need to penalize abbr-author mappings where the abbreviation has a much longer or shorter lifespan."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further, we notice that there are abbreviations that do not have an associated author. E.g. \"joka\", does not have any good fit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [01:46<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm.tqdm([row for _, row in author_mapping.iterrows()]):\n",
    "    abbr_authors = []\n",
    "    abbr = row[\"abbreviation\"]\n",
    "    mapped_author = row[\"name\"]\n",
    "    abbr_neighbours = list(G.neighbors(abbr))\n",
    "    for author in abbr_neighbours:\n",
    "        author_like = f\"%{json.dumps(author)}%\"\n",
    "        rows = cur.execute('select ar.published_at from articles ar where ar.author_array like ?', (author_like,)).fetchall()\n",
    "        type = \"mapped name\" if author == mapped_author else \"name\"\n",
    "        abbr_authors.extend([{\"author\": author, \"type\": type, \"published_at\": row[0]} for row in rows])\n",
    "\n",
    "    \n",
    "    abbr_like = f\"%{json.dumps(abbr)}%\"\n",
    "    rows = cur.execute('select ar.published_at from articles ar where ar.author_array like ?', (abbr_like,)).fetchall()\n",
    "    abbr_authors.extend([{\"author\": abbr, \"type\": \"abbreviation\", \"published_at\": row[0]} for row in rows])\n",
    "\n",
    "    abbr_authors = pd.DataFrame(columns=[\"author\", \"type\", \"published_at\"], data=abbr_authors)\n",
    "\n",
    "    # aggregate by quarter of the year\n",
    "    abbr_authors['published_at'] = pd.to_datetime(abbr_authors['published_at'])\n",
    "    abbr_authors['quarter'] = abbr_authors['published_at'].dt.quarter\n",
    "    abbr_authors['year'] = abbr_authors['published_at'].dt.year\n",
    "    abbr_authors['year_quarter'] = abbr_authors['year'].astype(str) + \"/\" + abbr_authors['quarter'].astype(str)\n",
    "    #abbr_authors['year_semester'] = abbr_authors['year'].astype(str) + \"/\" + abbr_authors['quarter'].apply(lambda x: 1 if x <= 2 else 2).astype(str)\n",
    "    abbr_authors = abbr_authors.groupby(['year_quarter', 'author', 'type']).count()['published_at'].reset_index()\n",
    "    # rename published at to count\n",
    "    abbr_authors = abbr_authors.rename(columns={\"published_at\": \"count\"})\n",
    "    \n",
    "    # fill year_quarter gaps\n",
    "    year_quarters = abbr_authors['year_quarter'].drop_duplicates()\n",
    "    # get min and max year\n",
    "    min_year = int(min(year_quarters).split(\"/\")[0])\n",
    "    max_year = int(max(year_quarters).split(\"/\")[0])\n",
    "    # get for min_year min quarter and for max_year max quarter\n",
    "    min_quarter = int(min([year_quarter.split(\"/\")[1] for year_quarter in year_quarters if year_quarter.split(\"/\")[0] == str(min_year)]))\n",
    "    max_quarter = int(max([year_quarter.split(\"/\")[1] for year_quarter in year_quarters if year_quarter.split(\"/\")[0] == str(max_year)]))\n",
    "    # create all year_quarters\n",
    "    year_quarters = [str(year) + \"/\" + str(quarter) for year in range(min_year, max_year + 1) for quarter in range(1, 5)]\n",
    "        \n",
    "    # for each author: if there is no entry for a unique combination of 'year_quarter', add it with count np.nan\n",
    "    index = pd.MultiIndex.from_product([year_quarters, abbr_authors['author'].unique()], names=['year_quarter', 'author'])\n",
    "    \n",
    "    # Reindex the DataFrame with the MultiIndex to fill in missing combinations with NaN\n",
    "    abbr_authors = abbr_authors.set_index(['year_quarter', 'author']).reindex(index, fill_value=None).reset_index()\n",
    "    \n",
    "    # set type for each author to first type of that author\n",
    "    abbr_authors['type'] = abbr_authors.groupby('author')['type'].transform('first')\n",
    "    \n",
    "    # sort by year_quarter and type\n",
    "    abbr_authors = abbr_authors.sort_values(by=['year_quarter', 'type'])\n",
    "    \n",
    "    directory = \"author_abbreviation_pairs\"\n",
    "\n",
    "    if {\"author\": mapped_author, \"abbreviation\": abbr} in author_abbreviation_pairs_with_lifespan_difference:\n",
    "        directory = \"author_abbreviation_pairs_with_lifespan_difference\"\n",
    "\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    sns.lineplot(data=abbr_authors, x='year_quarter', y='count', hue='author', style='type', errorbar=None, linewidth=2.5)\n",
    "    # set y title to article count\n",
    "    plt.ylabel(\"article count\")\n",
    "    plt.xlabel(\"year/quarter\")\n",
    "    sns.set(rc={'figure.figsize':(14,10)})\n",
    "    plt.xticks(rotation=-75)\n",
    "    # set ticks to every 4th\n",
    "    plt.xticks(np.arange(0, len(abbr_authors['year_quarter'].unique()), 4))\n",
    "    #plt.tight_layout()\n",
    "    plt.title(f'Article count of abbreviation {abbr}, associated authors and mapped author {mapped_author}')\n",
    "    plt.savefig(f'../reports/figures/{directory}/articles_written_by_abbreviation_{abbr}_and_mapped_author_{\"_\".join(mapped_author.split(\" \"))}_and_associated_authors.png',bbox_inches='tight',dpi=300)\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:17:14.375142216Z",
     "start_time": "2023-08-08T11:15:27.577279827Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mind the fact that seaborn lineplot connects non-neighbouring points. If more correct view is needed, choose scatterplot. See here for further infos: https://stackoverflow.com/questions/52098537/avoid-plotting-missing-values-on-a-line-plot\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Takeaways:\n",
    "* Author entities can have different names (compare Inge Engelhardt and Inge-Dore Engelhardt in \"articles_written_by_abbreviation_ie_and_mapped_author_Inge_Engelhardt_and_associated_authors\"\n",
    "  * an obvious szenario is that the author got married and changed their name\n",
    "* there are only few mappings where the abbreviation and the name share a similar article count distribution \n",
    "  * one good example is: articles_written_by_abbreviation_lyn_and_mapped_author_Evelyn_ter_Vehn_and_associated_authors\n",
    "  * one example for a more or less good similarity is: articles_written_by_abbreviation_hgw_and_mapped_author_Hanna_Gerwig_and_associated_authors\n",
    "  * one example for a match but with close to no similarity is: articles_written_by_abbreviation_krysta_and_mapped_author_Krysta_Brown_and_associated_authors \n",
    "  * a good example for the randomness in using the abbreviation or the name is: articles_written_by_abbreviation_mpu_and_mapped_author_Matthias_Puppe_and_associated_authors\n",
    "  * TODO: Calculate the similarity of abbr and mapped name distribution and all other names so that we can determine if the mapped\n",
    "    author is closer to the distribution of the abbreviation than all the other none mapped names\n",
    "  * TODO: Conclusion  \n",
    "\n",
    "Note:\n",
    "If an abbreviation or name has only written articles in one quarter and thus only one data point, it won't get displayed by seaborn\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new graph has 387 nodes and 183 edges\n"
     ]
    }
   ],
   "source": [
    "print(f\"new graph has {len(g_new.nodes)} nodes and {len(g_new.edges)} edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:17:59.760357923Z",
     "start_time": "2023-08-08T11:17:59.716121929Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are abbr nodes that were not matched with any author. That's why we have: edges * 2 < nodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbreviation node ast has no edges\n",
      "abbreviation node at has no edges\n",
      "abbreviation node ms has no edges\n",
      "abbreviation node nie has no edges\n",
      "abbreviation node mape has no edges\n",
      "abbreviation node mot has no edges\n",
      "abbreviation node mabe has no edges\n",
      "abbreviation node beck has no edges\n",
      "abbreviation node thomas has no edges\n",
      "abbreviation node th has no edges\n",
      "abbreviation node ter vehn has no edges\n",
      "abbreviation node döring has no edges\n",
      "abbreviation node isc has no edges\n",
      "abbreviation node grätz has no edges\n",
      "abbreviation node sag has no edges\n",
      "abbreviation node nag has no edges\n",
      "abbreviation node kreuz has no edges\n",
      "abbreviation node dei has no edges\n",
      "abbreviation node sie has no edges\n",
      "abbreviation node iro has no edges\n",
      "abbreviation node she has no edges\n"
     ]
    }
   ],
   "source": [
    "# test that only abbrs are not in the matches nodes\n",
    "for node in g_new.nodes:\n",
    "    if g_new.degree(node) == 0 and node in author_list:\n",
    "        print(f\"author node {node} has no edges\")\n",
    "    elif g_new.degree(node) == 0 and node in abbr_list:\n",
    "        print(f\"abbreviation node {node} has no edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:18:15.592655835Z",
     "start_time": "2023-08-08T11:18:15.551845890Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new neighbors of old abbr ast node neighbors Andreas Tappert are ['art']\n",
      "new neighbors of old abbr at node neighbors Andreas Tappert are ['art']\n",
      "new neighbors of old abbr ms node neighbors Melanie Steitz are ['mes']\n",
      "new neighbors of old abbr ms node neighbors Michael Strohmeyer are ['mey']\n",
      "new neighbors of old abbr ms node neighbors Mathias Schönknecht are ['mhs']\n",
      "new neighbors of old abbr nie node neighbors Nico Fliegner are ['nf']\n",
      "new neighbors of old abbr mape node neighbors Matthias Puppe are ['mpu']\n",
      "new neighbors of old abbr mot node neighbors Matthias Roth are ['mro']\n",
      "new neighbors of old abbr mabe node neighbors Mathias Orbeck are ['mo']\n",
      "new neighbors of old abbr mabe node neighbors Mario Beck are ['mario']\n",
      "new neighbors of old abbr beck node neighbors Mathias Orbeck are ['mo']\n",
      "new neighbors of old abbr beck node neighbors Mario Beck are ['mario']\n",
      "new neighbors of old abbr thomas node neighbors Thomas Sparrer are ['tsa']\n",
      "new neighbors of old abbr th node neighbors Thomas Haegeler are ['the']\n",
      "new neighbors of old abbr ter vehn node neighbors Jörg ter Vehn are ['ttr']\n",
      "new neighbors of old abbr döring node neighbors Frank Döring are ['fd']\n",
      "new neighbors of old abbr isc node neighbors Ilka Fischer are ['if']\n",
      "new neighbors of old abbr grätz node neighbors Saskia Grätz are ['saskia']\n",
      "new neighbors of old abbr sag node neighbors Saskia Grätz are ['saskia']\n",
      "new neighbors of old abbr nag node neighbors Hanna Gerwig are ['hgw']\n",
      "new neighbors of old abbr nag node neighbors Vanessa Gregor are ['vag']\n",
      "new neighbors of old abbr kreuz node neighbors Sabine Kreuz are ['sabine']\n",
      "new neighbors of old abbr dei node neighbors Ekkehard Schulreich are ['es']\n",
      "new neighbors of old abbr sie node neighbors Simone Prenzel are ['sp']\n",
      "new neighbors of old abbr iro node neighbors Steffi Robak are ['sro']\n",
      "new neighbors of old abbr she node neighbors Stephanie Helm are ['hem']\n"
     ]
    }
   ],
   "source": [
    "# list the abbreviations that were connected to the author that the edges with zero edges were pointing to\n",
    "# so we can e.g. check if we need to enable multiple abbreviations for the same author\n",
    "for node in g_new.nodes:\n",
    "    if g_new.degree(node) == 0:\n",
    "        # check the authors of the old graph that were pointing to this abbreviation\n",
    "        old_neighbors = G.neighbors(node)\n",
    "        for old_neighbor in old_neighbors:\n",
    "            print(f\"new neighbors of old abbr {node} node neighbors {old_neighbor} are {list(g_new.neighbors(old_neighbor))}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:18:24.668783217Z",
     "start_time": "2023-08-08T11:18:24.659054583Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this we do see that some authors have several abbreviations\n",
    "For example in an earlier analysis with no authors sorted out based on their article number: krysta brown has probably two abbreviations: \"krysta\" and \"brown\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 abbreviations were matched\n",
      "There are 21 abbreviations that were not matched\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(len(g_new.edges))} abbreviations were matched\")\n",
    "print(f\"There are {len(g_new.nodes) - (len(g_new.edges) * 2)} abbreviations that were not matched\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:19:25.652245396Z",
     "start_time": "2023-08-08T11:19:25.606439918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ast', 'at', 'ms', 'nie', 'mape', 'mot', 'mabe', 'beck', 'thomas', 'th', 'ter vehn', 'döring', 'isc', 'grätz', 'sag', 'nag', 'kreuz', 'dei', 'sie', 'iro', 'she']\n"
     ]
    }
   ],
   "source": [
    "# print not matched abbreviations\n",
    "print([node for node in g_new.nodes if g_new.degree(node) == 0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:19:30.810994045Z",
     "start_time": "2023-08-08T11:19:30.801795822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 abbreviations have only one edge in the old graph\n",
      "['ms', 'mabe', 'beck', 'nag']\n"
     ]
    }
   ],
   "source": [
    "# test if these abbreviations have only one edge in the old graph. If so, we can append them to that author.\n",
    "# assumes that the names got assigned a more fitting abbreviation but these here do also belong to that name\n",
    "unmatched_abbrs_with_only_one_edge = [node for node in g_new.nodes if g_new.degree(node) == 0 and len(list(G.neighbors(node))) == 1]\n",
    "print(f\"{len(unmatched_abbrs_with_only_one_edge)} abbreviations have only one edge in the old graph\")\n",
    "\n",
    "# list remaining abbreviations\n",
    "remaining_abbrs = [node for node in g_new.nodes if g_new.degree(node) == 0 and len(list(G.neighbors(node))) > 1]\n",
    "print(remaining_abbrs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T11:19:44.260120205Z",
     "start_time": "2023-08-08T11:19:44.219740570Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We conclude, that most of the unmatched abbreviations were only connected to one author originally. That means that we can append them to that author because we know now that authors can have multiple abbreviations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lvz_venv",
   "language": "python",
   "display_name": "lvz_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
